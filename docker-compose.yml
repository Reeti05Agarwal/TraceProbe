version: "3.8"
services:

  zookeeper:
    image: confluentinc/cp-zookeeper:7.2.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOO_4LW_COMMANDS_WHITELIST: "ruok"
    ports:
      - "2181:2181"
    networks:
      - ipdr-network
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'echo ruok | nc -w 2 localhost 2181'"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  kafka:
    image: confluentinc/cp-kafka:7.2.1
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    volumes:
      - kafka_data:/var/lib/kafka/data 
    networks:
      - ipdr-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server kafka:9092 > /dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5
    restart: always

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.6.2
    container_name: elasticsearch
    environment:
      - "discovery.type=single-node" 
      - "xpack.security.enabled=false"
    ports:
      - "9200:9200"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - es_data:/usr/share/elasticsearch/data 
    networks:
      - ipdr-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=5s"]
      interval: 15s
      timeout: 10s
      retries: 5
    restart: always

  kibana:
    image: docker.elastic.co/kibana/kibana:8.6.2
    container_name: kibana
    ports:
      - "5601:5601"
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - ipdr-network
    volumes:
      - ./templates:/templates 
    restart: always

  producer:
    build:
      context: .
      dockerfile: ./ipdr_analyzer/producer/Dockerfile
    container_name: producer
    environment:
      - LOG_FILE_PATH=/data/uploads
    volumes:
      - ./data/uploads:/data/uploads
    ports:
      - "5000:5000"
    depends_on:
      kafka:
        condition: service_started
    networks:
      - ipdr-network
    restart: on-failure

  frontend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "3000:3000"
    volumes:
      - ./data:/data 
    environment:
      UPLOAD_DIR: /data/uploads
      ELASTICSEARCH_URL: http://elasticsearch:9200
      KIBANA_URL: http://kibana:5601
      PRODUCER_URL: http://producer:5000
    env_file:
      - .env
    depends_on:
      - elasticsearch
      - kibana
      - producer
    networks:
      - ipdr-network
    restart: on-failure

  processor:
    build:
      context: .
      dockerfile: ./ipdr_analyzer/processor/Dockerfile
    container_name: processor
    env_file:
      - .env 
    dns:
      - 8.8.8.8
      - 1.1.1.1
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - ipdr-network
    restart: on-failure

  consumer:
    build:
      context: .
      dockerfile: ./ipdr_analyzer/consumer/Dockerfile
    container_name: consumer
    env_file:
      - .env
    depends_on:
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    networks:
      - ipdr-network
    restart: on-failure




networks:
  ipdr-network:
    driver: bridge

volumes:
  es_data:
    driver: local
  kafka_data:
    driver: local
